from pandas import read_csv, DataFrame
from itertools import product
from os.path import join, isfile
from snakemake.utils import min_version, validate
from snakemake.io import expand

__author__ = "Graeme Ford"
__credits__ = [
    "Graeme Ford",
    "Prof. Michael S. Pepper",
    "Prof. Fourie Joubert",
    "Fatima Barmania",
    "Megan Holborn",
]
__version__ = "1.0.0"
__maintainer__ = "Graeme Ford"
__email__ = "graeme.ford@tuks.co.za"
__status__ = "Development"

# Enforce version check
min_version("7")

# IMPORT SAMPLES METADATA
configfile: join("config", "manifest.json")
validate(config, join("..", "config", ".schema", "manifest.schema.json"))


# SET REPORT TEMPLATE
# report: "report/template.rst"

include: "rules/common.smk"

# IMPORT METADATA
locations = read_csv(join("input", "locations.csv"), header=0)
samples = read_csv(join("input", "samples.csv"), header=0)

# [IMPORT] Custom functions to connect checkpoints with variable outputs
include: "rules/checkpoint_connectors.smk"


# DEFINE CONTEXT-VARIABLES:
clusters = set([cluster for cluster in samples.keys() if cluster not in ["sample_name", "dataset"]])



rule extract_provided_region:
    log: out("tmp/{location}/extract_provided_region.log"),
    benchmark: out("tmp/{location}/extract_provided_region.benchmark")
    wildcard_constraints:
        location=r"[a-zA-Z0-9\-]+"
    params:
        fromBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_start"].item(),
        toBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_stop"].item(),
        chr=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item(),
        input=lambda wildcards, input: input["pgen"].replace('.pgen', ""),
        output=lambda wildcards, output: output["pgen"].replace(".pgen", ""),
    input:
        pgen=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.pgen"),
        pvar=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.pvar.zst"),
        psam=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.psam"),
    output:
        pgen=out("tmp/{location}/extract_provided_region.pgen"),
        pvar=out("tmp/{location}/extract_provided_region.pvar.zst"),
        psam=out("tmp/{location}/extract_provided_region.psam"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --from-bp {params.fromBP} --to-bp {params.toBP} --chr {params.chr} --make-pgen vzs --out {params.output} >{log} 2>&1
        """


rule remove_rare_variants:
    log: out("tmp/{contig}/removed_rare_variants.log"),
    benchmark: out("tmp/{contig}/removed_rare_variants.benchmark")
    wildcard_constraints: # TODO: Make this configurable
        contig=r"[0-9]{1,2}"
    params:
        input=lambda wildcards, input: input["pgen"].replace('.pgen', ""),
        output=lambda wildcards, output: output["pgen"].replace(".pgen", ""),
    input:
        pgen=out("tmp/{contig}/extract_provided_region.pgen"),
        pvar=out("tmp/{contig}/extract_provided_region.pvar.zst"),
        psam=out("tmp/{contig}/extract_provided_region.psam"),
        sample_metadata=out("tmp/formatted_sample_metadata/samples.tsv")
    output:
        pgen=out("tmp/{contig}/removed_rare_variants.pgen"),
        pvar=out("tmp/{contig}/removed_rare_variants.pvar.zst"),
        psam=out("tmp/{contig}/removed_rare_variants.psam"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --pheno {input.sample_metadata} --maf {config[parameters][rare-variant-frequency-cutoff]} --make-pgen vzs --out {params.output} >{log} 2>&1
        """   


checkpoint report_fixation_index_per_cluster:
    log: out("fixation_index/{cluster}/{location}/fixation_index_per_cluster.log")
    benchmark: out("fixation_index/{cluster}/{location}/fixation_index_per_cluster.benchmark")
    params:
        input=lambda wildcards, input: input["pgen"].replace(".pgen", ""),
        output=lambda wildcards: out(f"fixation_index/{wildcards.cluster}/{wildcards.location}/fixation_index_per_cluster")
    wildcard_constraints:
        cluster=r"[a-zA-Z0-9\-]+",
        location=r"[a-zA-Z0-9\-]+"
    input:
        pgen=out("tmp/{contig}/removed_rare_variants.pgen"),
        pvar=out("tmp/{contig}/removed_rare_variants.pvar.zst"),
        psam=out("tmp/{contig}/removed_rare_variants.psam"),
    output:
        fixation_report=directory(out("fixation_index/{cluster}/{location}/"))
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --fst {wildcards.cluster} report-variants zs --out {params.output} >{log} 2>&1
        """


rule generate_pca:
    log: out("generate_pca/{location}/pca.log")
    benchmark: out("generate_pca/{location}/pca.benchmark")
    wildcard_constraints: # TODO: Make this configurable
        contig=r"[0-9]{1,2}"
    params:
        fromBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_start"].item(),
        toBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_stop"].item(),
        chr=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item(),
        input=lambda wildcards, input: input["pgen"].replace(".pgen", ""),
        output=lambda wildcards: out(f"generate_pca/{wildcards.location}/pca")
    wildcard_constraints:
        cluster=r"[a-zA-Z0-9\-]+",
        location=r"[a-zA-Z0-9\-]+"
    input:
        pgen=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pgen"),
        pvar=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pvar.zst"),
        psam=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.psam"),
    output:
        eigenvectors=out("generate_pca/{location}/pca.eigenvec"),
        eigenvectorsPerAllele=out("generate_pca/{location}/pca.eigenvec.allele"),
        eigenvalues=out("generate_pca/{location}/pca.eigenval"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --from-bp {params.fromBP} --to-bp {params.toBP} --chr {params.chr} --pca allele-wts --out {params.output} >{log} 2>&1
        """


checkpoint calculate_linkage_disequilibrium_per_cluster:
    log: out("linkage_disequilibrium/{cluster}/{location}/calculated_linkage_disequilibrium_per_cluster.log")
    benchmark: out("linkage_disequilibrium/{cluster}/{location}/calculated_linkage_disequilibrium_per_cluster.benchmark")
    params:
        fromBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_start"].item(),
        toBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_stop"].item(),
        chr=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item(),
        input=lambda wildcards, input: input["pgen"].replace(".pgen", ""),
        output=lambda wildcards: out(f"linkage_disequilibrium/{wildcards.cluster}/{wildcards.location}/calculated_linkage_disequilibrium_per_cluster")
    wildcard_constraints:
        cluster=r"[a-zA-Z0-9\-]+",
        location=r"[a-zA-Z0-9\-]+"
    input:
        pgen=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pgen"),
        pvar=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pvar.zst"),
        psam=lambda wildcards: out(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.psam"),
    output:
        linkage_reports=directory(out("linkage_disequilibrium/{cluster}/{location}/"))
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --loop-cats {wildcards.cluster} --from-bp {params.fromBP} --to-bp {params.toBP} --chr {params.chr} --r2-unphased yes-really zs cols=chrom,pos,id,ref,alt,provref,maj --out {params.output} >{log} 2>&1
        """

rule all:
    """
    Full suite of analyses to describe population structure using both parametric and non-parametric methods.
    """
    default_target: True
    input:
        expand(out("tmp/{location}/extract_provided_region.pgen"), location=locations["location_name"].unique().tolist()),
        expand(out("tmp/{location}/extract_provided_region.pvar.zst"), location=locations["location_name"].unique().tolist()),
        expand(out("tmp/{location}/extract_provided_region.psam"), location=locations["location_name"].unique().tolist()),
        expand(out("tmp/{contig}/removed_rare_variants.pgen"), contig=locations["chromosome"].unique().tolist()),
        expand(out("tmp/{contig}/removed_rare_variants.pvar.zst"), contig=locations["chromosome"].unique().tolist()),
        expand(out("tmp/{contig}/removed_rare_variants.psam"), contig=locations["chromosome"].unique().tolist()),
        expand(out("generate_pca/{location}/pca.eigenvec"), location=locations["location_name"]),
        expand(out("generate_pca/{location}/pca.eigenvec.allele"), location=locations["location_name"]),
        expand(out("generate_pca/{location}/pca.eigenval"), location=locations["location_name"]),
        collect_calculate_linkage_disequilibrium_per_cluster(),
