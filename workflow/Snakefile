from pandas import read_csv, DataFrame
from itertools import product
from os.path import join, isfile
from snakemake.utils import min_version
from snakemake.io import expand

__author__ = "Graeme Ford"
__credits__ = [
    "Graeme Ford",
    "Prof. Michael S. Pepper",
    "Prof. Fourie Joubert",
    "Fatima Barmania",
    "Megan Holborn",
]
__version__ = "1.0.0"
__maintainer__ = "Graeme Ford"
__email__ = "graeme.ford@tuks.co.za"
__status__ = "Development"

# Enforce version check
min_version("7")

# IMPORT SAMPLES METADATA
configfile: join("config", "config.json")


# SET REPORT TEMPLATE
report: "report/template.rst"

include: "rules/common.smk"

# IMPORT SAMPLE METADATA
locations = read_csv(join("input", "locations.csv"), header=0)
samples = read_csv(join("input", "samples.csv"), header=0)

# SET CLUSTER CATEGORIES
cluster_assignments = set(
    [
        grouping_category
        for grouping_category in samples.keys()
        if grouping_category != "sample_name"
    ]
)

# DEFINE CONTEXT-VARIABLES:
bExtensions = ["bed", "bim", "fam"]
tExtensions = ["map", "ped"]


rule extract_provided_coordinates:
    log: outputDir("tmp/{location}/extracted_provided_coordinates.log"),
    benchmark: outputDir("tmp/{location}/extracted_provided_coordinates.benchmark")
    wildcard_constraints:
        location=r"[a-zA-Z0-9\-]+"
    params:
        fromBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_start"].item(),
        toBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_stop"].item(),
        chr=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item(),
        input=lambda wildcards, input: input["pgen"].replace('.pgen', ""),
        output=lambda wildcards, output: output["pgen"].replace(".pgen", ""),
    input:
        pgen=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.pgen"),
        pvar=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.pvar.zst"),
        psam=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_related_samples.psam"),
    output:
        pgen=outputDir("tmp/{location}/extracted_provided_coordinates.pgen"),
        pvar=outputDir("tmp/{location}/extracted_provided_coordinates.pvar.zst"),
        psam=outputDir("tmp/{location}/extracted_provided_coordinates.psam"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --from-bp {params.fromBP} --to-bp {params.toBP} --chr {params.chr} --make-pgen vzs --out {params.output} >{log} 2>&1
        """


rule remove_rare_variants:
    log: outputDir("tmp/{contig}/removed_rare_variants.log"),
    benchmark: outputDir("tmp/{contig}/removed_rare_variants.benchmark")
    wildcard_constraints: # TODO: Make this configurable
        contig=r"[0-9]{1,2}"
    params:
        input=lambda wildcards, input: input["pgen"].replace('.pgen', ""),
        output=lambda wildcards, output: output["pgen"].replace(".pgen", ""),
    input:
        pgen=outputDir("tmp/{contig}/removed_related_samples.pgen"),
        pvar=outputDir("tmp/{contig}/removed_related_samples.pvar.zst"),
        psam=outputDir("tmp/{contig}/removed_related_samples.psam"),
        sample_metadata=outputDir("tmp/formatted_sample_metadata/samples.tsv")
    output:
        pgen=outputDir("tmp/{contig}/extracted_provided_coordinates.pgen"),
        pvar=outputDir("tmp/{contig}/extracted_provided_coordinates.pvar.zst"),
        psam=outputDir("tmp/{contig}/extracted_provided_coordinates.psam"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --pheno {input.sample_metadata} --mac 2 --make-pgen vzs --out {params.output} >{log} 2>&1
        """   


checkpoint report_fixation_index_per_cluster:
    log: outputDir("fixation_index/{cluster}/{location}/fixation_index_per_cluster.log")
    benchmark: outputDir("fixation_index/{cluster}/{location}/fixation_index_per_cluster.benchmark")
    params:
        input=lambda wildcards, input: input["pgen"].replace(".pgen", ""),
        output=lambda wildcards: outputDir(f"fixation_index/{wildcards.cluster}/{wildcards.location}/fixation_index_per_cluster")
    wildcard_constraints:
        cluster=r"[a-zA-Z0-9\-]+",
        location=r"[a-zA-Z0-9\-]+"
    input:
        pgen=outputDir("tmp/{contig}/removed_rare_variants.pgen"),
        pvar=outputDir("tmp/{contig}/removed_rare_variants.pvar.zst"),
        psam=outputDir("tmp/{contig}/removed_rare_variants.psam"),
    output:
        fixation_report=directory(outputDir("fixation_index/{cluster}/{location}/"))
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --fst {wildcards.cluster} report-variants zs --out {params.output} >{log} 2>&1
        """


rule generate_pca:
    log: outputDir("generate_pca/{location}/pca.log")
    benchmark: outputDir("generate_pca/{location}/pca.benchmark")
    wildcard_constraints: # TODO: Make this configurable
        contig=r"[0-9]{1,2}"
    params:
        fromBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_start"].item(),
        toBP=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "ld_stop"].item(),
        chr=lambda wildcards: locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item(),
        input=lambda wildcards, input: input["pgen"].replace(".pgen", ""),
        output=lambda wildcards: outputDir(f"generate_pca/{wildcards.location}/pca")
    wildcard_constraints:
        cluster=r"[a-zA-Z0-9\-]+",
        location=r"[a-zA-Z0-9\-]+"
    input:
        pgen=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pgen"),
        pvar=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.pvar.zst"),
        psam=lambda wildcards: outputDir(f"tmp/{locations.loc[locations["location_name"] == wildcards.location, "chromosome"].item()}/removed_rare_variants.psam"),
    output:
        eigenvectors=outputDir("generate_pca/{location}/pca.eigenvec"),
        eigenvectorsPerAllele=outputDir("generate_pca/{location}/pca.eigenvec.allele"),
        eigenvalues=outputDir("generate_pca/{location}/pca.eigenval"),
    threads: workflow.cores * 0.25
    shell:
        """
        plink2 --threads {threads} --pfile {params.input} vzs --from-bp {params.fromBP} --to-bp {params.toBP} --chr {params.chr} --pca allele-wts --out {params.output} >{log} 2>&1
        """


rule all:
    """
    Full suite of analyses to describe population structure using both parametric and non-parametric methods.
    """
    default_target: True
    input:
        expand(outputDir("generate_pca/{location}/pca.eigenvec"), location=locations["location_name"]),
        expand(outputDir("generate_pca/{location}/pca.eigenvec.allele"), location=locations["location_name"]),
        expand(outputDir("generate_pca/{location}/pca.eigenval"), location=locations["location_name"])
