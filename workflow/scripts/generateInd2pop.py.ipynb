{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\frdgr\\\\OneDrive\\\\Documents\\\\University of Pretoria\\\\Population-Structure-Workflow'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import chdir, getcwd\n",
    "# chdir(\"..\")\n",
    "# chdir(\"..\")\n",
    "getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate `ind2pop` assignments\n",
    "\n",
    "This notebook describes the creation of `ind2pop` input data, a type of input based on `.fam` files produced by PLINK-1.9 and up.\n",
    "\n",
    "> To keep things simple, we will not cover infrastructure provisioning here. The `.fam` file will be 'provided' via `Snakemake` provisioning through a separate rule (`plinkPed`) to generate the ped file required to correctly order our labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\n",
    "We need to import and store our input datasets needed for this formatting operation. This includes:\n",
    "- *`samples.csv`* _(Our reference which describes our known population labels)_\n",
    "- *`results/{wildcards.cluster_assignment}/Population_Structure/fetchPedLables.pop`* _(Pedigree information for the relevant cluster as declared in `samples.csv`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snakemake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m samples \u001b[39m=\u001b[39m read_csv(snakemake\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39msamples, index_col\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msample_name\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m samples\n",
      "\u001b[1;31mNameError\u001b[0m: name 'snakemake' is not defined"
     ]
    }
   ],
   "source": [
    "samples = read_csv(snakemake.input.samples, index_col=\"sample_name\")\n",
    "samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the `.ped` file generated in a separate step.\n",
    "\n",
    "> For performance reasons, we do not want to import more than the first `IID` column since we only need it for ordering purposes. To get around this, we can use the `read_*` functions `usecols` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HGDP00747</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP00082</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP00735</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01416</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01077</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG02262</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03686</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG04141</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03857</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [HGDP00747, HGDP00082, HGDP00735, HGDP01229, HGDP01416, LP6005442-DNA-D01, LP6005441-DNA-C11, HGDP00244, HGDP00820, HGDP00478, HGDP00473, HGDP00577, HGDP00906, HGDP01418, HGDP00550, HGDP00734, HGDP00955, HGDP00896, HGDP01217, HGDP00201, HGDP00382, LP6005443-DNA-B02, HGDP00547, SS6004471, HG00477, HG00655, HG01243, HG01502, HG01579, HG01755, HG01780, HG01972, HG02077, HG02303, HG02587, HG02883, HG03034, HG03309, HG03620, HG03641, HG04175, NA19919, NA12815, NA18517, NA18561, NA18609, NA19190, NA18530, NA18868, NA18908, NA18993, NA19117, NA11932, NA19314, NA19319, NA20752, NA20765, NA19716, NA19795, NA19917, NA20856, NA20887, NA20902, NA21142, NA19922, HG00105, HG00384, NA20274, NA20321, HG01061, HG01073, HG01137, HG01384, HG01632, HG01920, HG01596, HG01710, HG00982, HG02190, HG01784, HG02053, HG02395, HG02449, HG02840, HG02851, HG03123, HG02728, HG03267, HG03270, HG03196, HG03823, HG03829, HG03941, HG03693, HG03882, HG01077, HG02262, HG03686, HG04141, HG03857]\n",
       "\n",
       "[100 rows x 0 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedLabels = read_csv(snakemake.input.ped\", usecols=[0], index_col=[\"ID\"], names=[\"ID\"], sep=\" \")\n",
    "pedLabels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate `ind2pop`\n",
    "\n",
    "We have a reference for a give samples cluster assignment. We also have a `Series` containing the required `sample_name` order. TO combine these, we can use the Pandas `.merge()` method to left-merge the sample assignment columns in `samples.csv` onto the `Series`, using the `Series` as index to set order.\n",
    "\n",
    "> We will need to use the `.fillna(\"-\")` function with a `-` ad Admixture-1.3.0 requests this syntax for samples with unknown assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>SUPER</th>\n",
       "      <th>SUB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HGDP00747</th>\n",
       "      <td>HGDP</td>\n",
       "      <td>East_Asia</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP00082</th>\n",
       "      <td>HGDP</td>\n",
       "      <td>Central_South_Asia</td>\n",
       "      <td>Balochi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP00735</th>\n",
       "      <td>HGDP</td>\n",
       "      <td>Middle_East</td>\n",
       "      <td>Palestinian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01229</th>\n",
       "      <td>HGDP</td>\n",
       "      <td>East_Asia</td>\n",
       "      <td>Mongola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01416</th>\n",
       "      <td>HGDP</td>\n",
       "      <td>Africa</td>\n",
       "      <td>BantuKenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG01077</th>\n",
       "      <td>1000 Genomes</td>\n",
       "      <td>AMR</td>\n",
       "      <td>PUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG02262</th>\n",
       "      <td>1000 Genomes</td>\n",
       "      <td>AMR</td>\n",
       "      <td>PEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03686</th>\n",
       "      <td>1000 Genomes</td>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG04141</th>\n",
       "      <td>1000 Genomes</td>\n",
       "      <td>SAS</td>\n",
       "      <td>BEB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG03857</th>\n",
       "      <td>1000 Genomes</td>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset               SUPER          SUB\n",
       "ID                                                      \n",
       "HGDP00747          HGDP           East_Asia     Japanese\n",
       "HGDP00082          HGDP  Central_South_Asia      Balochi\n",
       "HGDP00735          HGDP         Middle_East  Palestinian\n",
       "HGDP01229          HGDP           East_Asia      Mongola\n",
       "HGDP01416          HGDP              Africa   BantuKenya\n",
       "...                 ...                 ...          ...\n",
       "HG01077    1000 Genomes                 AMR          PUR\n",
       "HG02262    1000 Genomes                 AMR          PEL\n",
       "HG03686    1000 Genomes                 SAS          STU\n",
       "HG04141    1000 Genomes                 SAS          BEB\n",
       "HG03857    1000 Genomes                 SAS          STU\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pedLabels.merge(samples, how=\"left\", right_index=True, left_index=True).fillna(\"-\")\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "Here, we iterate over the columns in our newly transposed sample-assignment `DataFrame`, and save each to a corresponding `.pop` file for Admixture-1.3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[[snakemake.wildcards.cluster_assignment]].to_csv(f\"results/{snakemake.wildcards.cluster_assignment}/Population_Structure/fetchPedLables.pop\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
